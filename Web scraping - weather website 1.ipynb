{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94395188-905a-40e8-ac1a-21160b60b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Today in Raja Annamalai Puram, Tamil Nadu\n",
      "High/Low: --\n",
      "Wind: Wind Direction13 km/h\n",
      "Humidity: 57%\n",
      "Dew Point: 21°\n",
      "Pressure: Arrow Down1013.9 mb\n",
      "UV Index: 3 of 11\n",
      "Visibility: 11.27 km\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "# Script Name: Web Sraping using python                                              #\n",
    "# Objective: Scrapes weather details and hourly forecast from a weather website.     #\n",
    "# Date Created: 02/02/2024     DATE MODIFIED: 07/02/2024                             #\n",
    "# Team Name: Vel Pari                                                                #               \n",
    "######################################################################################\n",
    "# Step 1: Import necessary libraries                                                 #\n",
    "# Step 2: Initialize logging                                                         #\n",
    "# Step 3: Read the configuration file                                                #\n",
    "# Step 4: Retrieve the URL from the configuration file                               #\n",
    "# Step 5: Try to send a GET request to the URL                                       #\n",
    "# Step 6: Check if the request was successful (status code 200)                      #\n",
    "# Step 7: Extract the weather details container                                      #\n",
    "# Step 8: If the request was not successful:                                         #             \n",
    "# Step 9: Catch any exceptions that occur during the process                         #\n",
    "# Step 10: Log the end of the script                                                 #\n",
    "######################################################################################\n",
    "\n",
    "# Step 1: Importing necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import configparser\n",
    " \n",
    "# Step 2: Initialize logging\n",
    "log_path = r'C:\\Users\\Kaviyaa.Velraman\\Documents\\python\\Web_Scraping_using_python\\02_Log_files\\scraping_log.log'  # Specify the log file path\n",
    " \n",
    "# Truncate the log file if it exists\n",
    "if os.path.exists(log_path):\n",
    "    open(log_path, 'w').close()\n",
    " \n",
    "logging.basicConfig(filename=log_path, level=logging.INFO, format='%(levelname)s,%(message)s,%(asctime)s')\n",
    "logging.info('Step 1: Logging initialized.')\n",
    "\n",
    "# Get the path to the desktop \n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    " \n",
    "# Path to the configuration file\n",
    "config_file_path = os.path.join(desktop_path, \"webscraping.ini\")\n",
    " \n",
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file_path)\n",
    " \n",
    "# Step 3: Retrieve the URL from the configuration file\n",
    "url = config['Data']['url']\n",
    "logging.info('Step 2: URL retrieved from the configuration file.')\n",
    " \n",
    "try:\n",
    "    # Log step 4\n",
    "    logging.info('Step 3: Trying to send a GET request to the URL.')\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    " \n",
    "    # Step 5: Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Log step 5\n",
    "        logging.info('Step 4: Request successful, parsing HTML content.')\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Step 6: Extract the weather details container\n",
    "        logging.info('Step 5: Searching for weather details container.')\n",
    "        weather_details = soup.find('div', {'id': 'todayDetails'})\n",
    "        # Step 7: Extract individual weather details\n",
    "        if weather_details:\n",
    "            logging.info('Step 6: Weather details container found, extracting individual details.')\n",
    "            weather_today_header = weather_details.find('header').find('h2').text\n",
    "            print(weather_today_header)\n",
    "            weather_items = weather_details.find_all('div', {'class': 'WeatherDetailsListItem--WeatherDetailsListItem--1CnRC'})\n",
    "            for item in weather_items:\n",
    "                label = item.find('div', {'class': 'WeatherDetailsListItem--label--2ZacS'})\n",
    "                value = item.find('span', {'data-testid': True})\n",
    "                if label and value:\n",
    "                    print(f\"{label.text}: {value.text}\")\n",
    "        else:\n",
    "            print(\"Weather details not found.\")\n",
    "            logging.warning('Step 7: Weather details container not found.')\n",
    " \n",
    "    else:\n",
    "        # If the request was not successful, print an error message\n",
    "        error_message = f\"Failed to retrieve the page. Status code: {response.status_code}\"\n",
    "        print(error_message)\n",
    "        # Log step 5 failure\n",
    "        logging.error(error_message)\n",
    " \n",
    "# Step 8: Catch any exceptions that occur during the process and print an error message\n",
    "except Exception as e:\n",
    "    error_message = f\"An error occurred during scraping: {e}\"\n",
    "    print(error_message)\n",
    "    # Log step 8 failure\n",
    "    logging.error(error_message)\n",
    " \n",
    "# Log the end of the script\n",
    "finally:\n",
    "    logging.info('Script ended at: %s', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
